# DiTree

[project page](https://sites.google.com/view/ditree/home) , [paper](https://arxiv.org/abs/2508.21001)

Official implementation of the paper "Train Once Plan Anywhere Kinodynamic Motion Planning via Diffusion Trees" [CoRL 25]

This repository contains the code and experiment setup for  **Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees** . It includes training configuration, experiment execution scripts, and pretrained model checkpoints.

The associated car dataset and model weights are available for download [here](https://drive.google.com/drive/folders/1WiBU2g1qQn_2j6v1ZTB1eU0dAyCGoX7F?usp=sharing).

---

## ðŸ“¦ Installation

We recommend creating a Python virtual environment before installing dependencies.

1. **Clone the repository**

```bash
git clone https://github.com/Yanivhass/ditree.git
cd ditree
```

2. **Create a virtual environment**

```bash
python3 -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows
```

3. **Install PyTorch**
   Visit [PyTorch.org](https://pytorch.org/get-started/locally/) to find the correct installation command for your system (CPU or GPU).
   Example (CUDA 11.8):

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

4. **Install other dependencies**

```bash
pip install -r requirements.txt
```

---

## ðŸ“‚ Project Structure

```
.
â”œâ”€â”€ run_scenarios.py      # Runs the experiments
â”œâ”€â”€ train_manager.py      # Configures and launches training sessions
â”œâ”€â”€ checkpoints/          # Contains pretrained model weights
â”œâ”€â”€ data/                 # (optional) Local dataset storage
â””â”€â”€ requirements.txt      # Python dependencies
```

---

## ðŸš€ Usage

### Running Experiments

```bash
python run_scenarios.py
```

### Training

```bash
python train_manager.py
```

---

## ðŸ“¥ Pretrained Models & Dataset

Pretrained model weights and the car dataset can be downloaded from:
[Google Drive Link](https://drive.google.com/drive/folders/1WiBU2g1qQn_2j6v1ZTB1eU0dAyCGoX7F?usp=sharing)
AntMaze dataset is available using Minari  [Minari]([https://pytorch.org/get-started/locally/](https://minari.farama.org/index.html))
Place the downloaded files into:

```
checkpoints/
data/
```

## Citation

If you use this work, please cite:

```bibtex
@inproceedings{
hassidof2025trainonce,
title={Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees},
author={Yaniv Hassidof and Tom Jurgenson and Kiril Solovey},
booktitle={9th Annual Conference on Robot Learning},
year={2025},
url={https://openreview.net/forum?id=lJWUourMTT}
}





